{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115f3173",
   "metadata": {},
   "source": [
    "This notebook have 2 main usages:\n",
    "- Reduce train and test images **before downloading CLOC** (39 million might be too many, use sampling to get only a small portion). This output new metadata files for the new train and test set.\n",
    "- Cleans up the metadata for the CLOC dataset **after downloading CLOC**. CLOC dataset provides a huge list of image URLs hosted in Flickr server. However, some of these URLs may no longer be valid. This notebook removes these invalid URLs in the metadata of the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bceb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d15fc98",
   "metadata": {},
   "source": [
    "## Get a small portion of test and training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6615d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TEST_IMAGES = 10000 \n",
    "NUM_TRAIN_IMAGES = 500000\n",
    "\n",
    "original_metadata_path = \"/mnt/hdd/continuallearning/CLOC/data_preparation/release/\"\n",
    "new_metadata_path = \"/mnt/hdd/cloc/CLOC/data_preparation/release/small/\"\n",
    "test_file = \"yfcc100m_metadata_with_labels_usedDataRatio0.05_t110000_t250_valid_files_2004To2014_compact_val.csv\"\n",
    "download_link_and_locations = \"download_link_and_locations.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ff6d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_file():\n",
    "    lines = []\n",
    "    with open(original_metadata_path + test_file, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    assert NUM_TEST_IMAGES <= len(lines), \"NUM_TEST_IMAGES is more than number of lines in test_file\"\n",
    "    selected_lines = random.sample(lines, NUM_TEST_IMAGES)\n",
    "    with open(new_metadata_path + test_file, \"w\") as file:\n",
    "        file.writelines(selected_lines)\n",
    "\n",
    "    print(f\"{NUM_TEST_IMAGES} random lines have been written to small/{test_file}\")\n",
    "\n",
    "def generate_train_files():\n",
    "    print(\"Loading train data files...\")\n",
    "    labels = torch.load(original_metadata_path + 'train_labels.torchSave')\n",
    "    time_taken = torch.load(original_metadata_path + 'train_time.torchSave')\n",
    "    user = torch.load(original_metadata_path + 'train_user.torchSave')\n",
    "    userID = torch.load(original_metadata_path + 'train_userID.torchSave')\n",
    "    store_loc = torch.load(original_metadata_path + 'train_store_loc.torchSave')\n",
    "    print(f\"Sampling {NUM_TRAIN_IMAGES} images from the train data files...\")\n",
    "    \n",
    "    num_train_images = len(labels)\n",
    "    assert NUM_TRAIN_IMAGES <= num_train_images, \"NUM_TRAIN_IMAGES is more than number of images in train set\"\n",
    "    random_indices = random.sample(range(num_train_images), NUM_TRAIN_IMAGES)\n",
    "    \n",
    "    new_labels = [labels[i] for i in random_indices]\n",
    "    new_time_taken = [time_taken[i] for i in random_indices]\n",
    "    new_user = [user[i] for i in random_indices]\n",
    "    new_userID = [userID[i] for i in random_indices]\n",
    "    new_store_loc = [store_loc[i] for i in random_indices]\n",
    "    \n",
    "    # Define the new paths for saving the data\n",
    "    new_labels_path = new_metadata_path + 'train_labels.torchSave'\n",
    "    new_time_taken_path = new_metadata_path + 'train_time.torchSave'\n",
    "    new_user_path = new_metadata_path + 'train_user.torchSave'\n",
    "    new_userID_path = new_metadata_path + 'train_userID.torchSave'\n",
    "    new_store_loc_path = new_metadata_path + 'train_store_loc.torchSave'\n",
    "    \n",
    "    print(\"Saving to new train data files...\")\n",
    "\n",
    "    # Save the selected data to the new files\n",
    "    torch.save(new_labels, new_labels_path)\n",
    "    torch.save(new_time_taken, new_time_taken_path)\n",
    "    torch.save(new_user, new_user_path)\n",
    "    torch.save(new_userID, new_userID_path)\n",
    "    torch.save(new_store_loc, new_store_loc_path)\n",
    "\n",
    "def generate_download_link_and_locations():\n",
    "    labels = torch.load(new_metadata_path + 'train_labels.torchSave')\n",
    "    time_taken = torch.load(new_metadata_path + 'train_time.torchSave')\n",
    "    user = torch.load(new_metadata_path + 'train_user.torchSave')\n",
    "    userID = torch.load(new_metadata_path + 'train_userID.torchSave')\n",
    "    store_loc = torch.load(new_metadata_path + 'train_store_loc.torchSave')\n",
    "    print(\"Loading train data files...\")\n",
    "    assert(len(labels) == NUM_TRAIN_IMAGES)\n",
    "    test_lines = []\n",
    "    with open(new_metadata_path + test_file, \"r\") as file:\n",
    "        test_lines = file.readlines()\n",
    "    \n",
    "    valid = {}\n",
    "    for i in range(len(test_lines)):\n",
    "        line_splitted = test_lines[i].split(\",\")\n",
    "        loc = line_splitted[-1][:-1].strip()\n",
    "        valid[loc] = True\n",
    "    for i in range(len(labels)):\n",
    "        loc = store_loc[i].strip()\n",
    "        valid[loc] = True\n",
    "    \n",
    "    print(\"Saving to new download csv file...\")\n",
    "    lines = []\n",
    "    with open(original_metadata_path + download_link_and_locations, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    print(len(lines))\n",
    "    prefix = \"images/\"\n",
    "    selected_lines = []\n",
    "    first = False\n",
    "    for line in lines:\n",
    "        line_splitted = line.split(\",\")\n",
    "        assert(len(line_splitted) == 2)\n",
    "        loc = line_splitted[1][len(prefix):].strip()\n",
    "        if loc in valid:\n",
    "            selected_lines.append(line)\n",
    "    print(len(selected_lines))\n",
    "    # Write the selected lines to the new CSV file\n",
    "    with open(new_metadata_path + download_link_and_locations, \"w\") as output_file:\n",
    "        output_file.writelines(selected_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aaf71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_test_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41332a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required ~ 10 GB Ram free to run this\n",
    "generate_train_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330a6928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required ~ 8 GB Ram free to run this\n",
    "generate_download_link_and_locations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0f03a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/mnt/hdd/cloc/CLOC/data_preparation/download_images/dataset/images/\"\n",
    "metadata_path = \"/mnt/hdd/cloc/CLOC/data_preparation/release/small/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a4cc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert root != \"/path/to/CLOC/release/dataset/images/\", \"Please provide a valid path\"\n",
    "assert metadata_path != \"/path/to/CLOC/metadata/\", \"Please provide a valid path\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd22827",
   "metadata": {},
   "source": [
    "# Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dd5bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.load(metadata_path + 'train_labels.torchSave')\n",
    "time_taken = torch.load(metadata_path + 'train_time.torchSave')\n",
    "user = torch.load(metadata_path + 'train_user.torchSave')\n",
    "userID = torch.load(metadata_path + 'train_userID.torchSave')\n",
    "store_loc = torch.load(metadata_path + 'train_store_loc.torchSave')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0531f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a343b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether each image pointer exists in the downloaded files, if so add it to the index_list\n",
    "index_list = []\n",
    "for i in tqdm(range(len(labels))):\n",
    "    path = root + store_loc[i].strip()\n",
    "    if os.path.isfile(path):\n",
    "        index_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d2e538",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_clean = [labels[i] for i in index_list]\n",
    "time_taken_clean = [time_taken[i] for i in index_list]\n",
    "user_clean = [user[i] for i in index_list]\n",
    "userID_clean = [userID[i] for i in index_list]\n",
    "store_loc_clean = [store_loc[i] for i in index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55060432",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df6c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(labels_clean) > 0, \"Something went wrong, ensure that the root path is valid.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94807ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may perform some sanity checks before overwriting the original CLOC metadata with the following files.\n",
    "torch.save(labels_clean, metadata_path + 'train_labels.torchSave')\n",
    "torch.save(time_taken_clean, metadata_path + 'train_time.torchSave')\n",
    "torch.save(user_clean, metadata_path + 'train_user.torchSave')\n",
    "torch.save(userID_clean, metadata_path + 'train_userID.torchSave')\n",
    "torch.save(store_loc_clean, metadata_path + 'train_store_loc.torchSave')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0811a6c7",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f593a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_file = \"yfcc100m_metadata_with_labels_usedDataRatio0.05_t110000_t250_valid_files_2004To2014_compact_val.csv\"\n",
    "df = pd.read_csv(metadata_path + test_set_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceb990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4be0bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce04241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether each image pointer exists in the downloaded files, if so add it to the index_list\n",
    "index_list = []\n",
    "for i in tqdm(range(len(df.iloc[:,4]))):\n",
    "    path = root + df.iloc[i,4].strip()\n",
    "    if os.path.isfile(path):\n",
    "        index_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e73f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.iloc[index_list,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324be946",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c23e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(index_list) > 0, \"Something went wrong, ensure that the root path is valid.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8927cc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(metadata_path + test_set_file, index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
